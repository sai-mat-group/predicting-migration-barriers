{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3a00b7-d256-4d92-9e32-e519e6c0cea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jarvis.core.graphs import Graph\n",
    "from jarvis.core.atoms import Atoms\n",
    "\n",
    "from pymatgen.io.jarvis import JarvisAtomsAdaptor\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "#from alignn.models.alignn import ALIGNN\n",
    "from alignn_multi import ALIGNN\n",
    "\n",
    "#from alignn.data import get_torch_dataset\n",
    "from data_multi import get_torch_dataset\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88cc544-0674-4da2-bbd2-e8aae216d782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoms_to_graph(atoms, cutoff=6.0, max_neighbors=12,\n",
    "    atom_features=\"cgcnn\", use_canonize=True):\n",
    "    \"\"\"Convert structure dict to DGLGraph.\"\"\"\n",
    "    #structure = Atoms.from_dict(atoms)\n",
    "    structure = JarvisAtomsAdaptor.get_atoms(Structure.from_dict(atoms))\n",
    "    return Graph.atom_dgl_multigraph(\n",
    "        structure,\n",
    "        cutoff=cutoff,\n",
    "        atom_features=atom_features,\n",
    "        max_neighbors=max_neighbors,\n",
    "        compute_line_graph=True,\n",
    "        use_canonize=use_canonize,\n",
    "    )\n",
    "\n",
    "def group_decay(model):\n",
    "    \"\"\"Omit weight decay from bias and batchnorm params.\"\"\"\n",
    "    decay, no_decay = [], []\n",
    "\n",
    "    for name, p in model.named_parameters():\n",
    "        if \"bias\" in name or \"bn\" in name or \"norm\" in name:\n",
    "            no_decay.append(p)\n",
    "        else:\n",
    "            decay.append(p)\n",
    "\n",
    "    return [\n",
    "        {\"params\": decay},\n",
    "        {\"params\": no_decay, \"weight_decay\": 0},\n",
    "    ]\n",
    "\n",
    "def collate_line_graph(samples):\n",
    "        \"\"\"Dataloader helper to batch graphs cross `samples`.\"\"\"\n",
    "        graphs, line_graphs, has_prop, labels = map(list, zip(*samples))\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        batched_line_graph = dgl.batch(line_graphs)\n",
    "        #print(labels[0])\n",
    "        #print(labels[0].size())\n",
    "        if len(labels[0].size()) > 0:\n",
    "            return batched_graph, batched_line_graph, torch.stack(has_prop), torch.stack(labels)\n",
    "        else:\n",
    "            return batched_graph, batched_line_graph, torch.stack(has_prop), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa17652-e809-487e-8d6b-7b04d400f082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ALIGNN(n_outputs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdbe8801-cfa0-4566-9d88-b17f90c4eabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First set up the optimiser, loss and device\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "params = group_decay(model)\n",
    "optimizer = torch.optim.AdamW(params, lr=1e-4)\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d2e9a1-4e91-43f8-8a55-25096fa41aae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9b185d849c4520814836ac60914f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = '../data/No-dup-complete_dataset_100.json'\n",
    "with open(data, \"rb\") as f:\n",
    "    dataset = json.loads(f.read())\n",
    "    \n",
    "for datum in tqdm_notebook(dataset):\n",
    "    datum['atoms'] = Atoms.to_dict(JarvisAtomsAdaptor.get_atoms(Structure.from_dict(datum['structure'])))\n",
    "    datum['has_prop'] = torch.FloatTensor(datum['OH']) \n",
    "    datum['target'] = torch.FloatTensor(datum['prop_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d43c6-1a8b-4b93-93a7-9313cc988aab",
   "metadata": {},
   "source": [
    "## Try Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70998ddf-fe15-456f-a025-4a28a0741d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 0.59231305 -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:01<00:00, 81.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: could not load CGCNN features for 103\n",
      "Setting it to max atomic number available here, 103\n",
      "warning: could not load CGCNN features for 101\n",
      "Setting it to max atomic number available here, 103\n",
      "warning: could not load CGCNN features for 102\n",
      "Setting it to max atomic number available here, 103\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 1221.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 0.5902975 -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 85.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 678.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = get_torch_dataset(dataset[:90], target='target', neighbor_strategy=\"k-nearest\", atom_features=\"cgcnn\", line_graph=True)\n",
    "val_data = get_torch_dataset(dataset[-10:], target='target', neighbor_strategy=\"k-nearest\", atom_features=\"cgcnn\", line_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfd556a-a2dd-47c5-b2b9-567ba98d25fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ignite.engine import (\n",
    "    Events,\n",
    "    create_supervised_evaluator,\n",
    "    create_supervised_trainer,\n",
    ")\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d80d4bb-fa6b-4018-8205-52bcceec113f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "collate_fn = collate_line_graph\n",
    "train_loader = DataLoader(train_data, batch_size=5, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=5, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72219325-10ba-4735-8fed-3f37db5cca24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ignite.metrics import Loss, MeanAbsoluteError\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "params = group_decay(model)\n",
    "optimizer = torch.optim.AdamW(params, lr=1e-4)\n",
    "\n",
    "metrics = {\"loss\": Loss(criterion), \"mae\": MeanAbsoluteError()}\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31910b9b-0ea4-4563-8967-3744cee28ce3",
   "metadata": {},
   "source": [
    "## Set up trainer and evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34232f36-84f7-4fd6-beb1-1a1d25debf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        prepare_batch=train_loader.dataset.prepare_batch,\n",
    "        device=device,\n",
    "        deterministic=False,\n",
    "        # output_transform=make_standard_scalar_and_pca,\n",
    "    )\n",
    "\n",
    "evaluator = create_supervised_evaluator(\n",
    "        model,\n",
    "        metrics=metrics,\n",
    "        prepare_batch=val_loader.dataset.prepare_batch,\n",
    "        device=device,\n",
    "        #\n",
    "   )\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(\n",
    "        model,\n",
    "        metrics=metrics,\n",
    "        prepare_batch=val_loader.dataset.prepare_batch,\n",
    "        device=device,\n",
    "        #\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e94e3b-d2c7-4ed6-812c-ce1ce181eb39",
   "metadata": {},
   "source": [
    "## Set up checkpoint saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a947136b-5f43-4446-9205-b36123580b90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7f0874f5b550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.handlers import Checkpoint, DiskSaver\n",
    "# where to save\n",
    "checkpoint_dir = './'\n",
    "# what to save\n",
    "to_save = {\n",
    "            \"model\": model,\n",
    "            \"optimizer\": optimizer,\n",
    "           # \"lr_scheduler\": scheduler,\n",
    "            \"trainer\": trainer,\n",
    "          }\n",
    "# what to check\n",
    "def cp_score(engine):\n",
    "    \"\"\"Lower MAE is better.\"\"\"\n",
    "    return -engine.state.metrics[\"mae\"]\n",
    "\n",
    "# save last two epochs\n",
    "evaluator.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED,\n",
    "            Checkpoint(\n",
    "                to_save,\n",
    "                DiskSaver(\n",
    "                    checkpoint_dir, create_dir=True, require_empty=False\n",
    "                ),\n",
    "                n_saved=2,\n",
    "                global_step_transform=lambda *_: trainer.state.epoch,\n",
    "            ),\n",
    "        )\n",
    "# save best model\n",
    "evaluator.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED,\n",
    "            Checkpoint(\n",
    "                to_save,\n",
    "                DiskSaver(\n",
    "                    checkpoint_dir, create_dir=True, require_empty=False\n",
    "                ),\n",
    "                filename_pattern=\"best_model.{ext}\",\n",
    "                n_saved=1,\n",
    "                global_step_transform=lambda *_: trainer.state.epoch,\n",
    "                score_function=cp_score,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72833868-7a36-4283-af05-956be879b893",
   "metadata": {},
   "source": [
    "## Logging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2233dab6-398a-4f06-87f5-5fbb10b0223a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import EarlyStopping\n",
    "from ignite.handlers.stores import EpochOutputStore\n",
    "from jarvis.db.jsonutils import dumpjson\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "history = {\n",
    "        \"train\": {m: [] for m in metrics.keys()},\n",
    "        \"validation\": {m: [] for m in metrics.keys()},\n",
    "    }\n",
    "\n",
    "eos = EpochOutputStore()\n",
    "eos.attach(evaluator)\n",
    "train_eos = EpochOutputStore()\n",
    "train_eos.attach(train_evaluator)\n",
    "\n",
    "# collect evaluation performance\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_results(engine):\n",
    "    \"\"\"Print training and validation metrics to console.\"\"\"\n",
    "    train_evaluator.run(train_loader)\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "    tmetrics = train_evaluator.state.metrics\n",
    "    vmetrics = evaluator.state.metrics\n",
    "    for metric in metrics.keys():\n",
    "        tm = tmetrics[metric]\n",
    "        vm = vmetrics[metric]\n",
    "        if metric == \"roccurve\":\n",
    "            tm = [k.tolist() for k in tm]\n",
    "            vm = [k.tolist() for k in vm]\n",
    "        if isinstance(tm, torch.Tensor):\n",
    "            tm = tm.cpu().numpy().tolist()\n",
    "            vm = vm.cpu().numpy().tolist()\n",
    "\n",
    "        history[\"train\"][metric].append(tm)\n",
    "        history[\"validation\"][metric].append(vm)\n",
    "        \n",
    "    dumpjson(\n",
    "         filename=\"history_val.json\",\n",
    "         data=history[\"validation\"],\n",
    "        )\n",
    "    dumpjson(\n",
    "        filename=\"./history_train.json\",\n",
    "        data=history[\"train\"],\n",
    "        )\n",
    "    \n",
    "    pbar = ProgressBar()\n",
    "    pbar.log_message(\"  #######  \")\n",
    "    pbar.log_message(f\"Train_MAE: {tmetrics['mae']:.4f}\")\n",
    "    pbar.log_message(f\"Val_MAE: {vmetrics['mae']:.4f}\")\n",
    "    pbar.log_message(\"    \")\n",
    "    \n",
    "    es_handler = EarlyStopping(\n",
    "            patience=10,\n",
    "            score_function=cp_score,\n",
    "            trainer=trainer,\n",
    "            )\n",
    "    evaluator.add_event_handler(Events.EPOCH_COMPLETED, es_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba318a5-a1ee-40cb-b521-6739d1b5a995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keeeto/mambaforge/envs/alignn-2/lib/python3.9/site-packages/pytorch_ignite-0.5.0.dev20230620-py3.9.egg/ignite/contrib/handlers/tqdm_logger.py:126: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.attach(trainer, output_transform=lambda x: {\"loss\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85defdc2-3382-4b8f-906a-af576931bbc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keeeto/mambaforge/envs/alignn-2/lib/python3.9/site-packages/dgl-1.1.0-py3.9-linux-x86_64.egg/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/18]   6%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #######  \n",
      "Train_MAE: 3.7610\n",
      "Val_MAE: 3.3779\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/18]   6%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #######  \n",
      "Train_MAE: 3.6870\n",
      "Val_MAE: 3.1636\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/18]   6%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #######  \n",
      "Train_MAE: 1.8919\n",
      "Val_MAE: 1.6817\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/18]   6%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #######  \n",
      "Train_MAE: 1.4204\n",
      "Val_MAE: 1.4924\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97803ec4f9a64630ba07197e6e0a50b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/18]   6%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa38d1-111f-4056-a800-2557cfdfcc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
