{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a00b7-d256-4d92-9e32-e519e6c0cea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jarvis.core.graphs import Graph\n",
    "from jarvis.core.atoms import Atoms\n",
    "\n",
    "from pymatgen.io.jarvis import JarvisAtomsAdaptor\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "#from alignn.models.alignn import ALIGNN\n",
    "from alignn_multi import ALIGNN\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cc544-0674-4da2-bbd2-e8aae216d782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atoms_to_graph(atoms, cutoff=6.0, max_neighbors=12,\n",
    "    atom_features=\"cgcnn\", use_canonize=True):\n",
    "    \"\"\"Convert structure dict to DGLGraph.\"\"\"\n",
    "    #structure = Atoms.from_dict(atoms)\n",
    "    structure = JarvisAtomsAdaptor.get_atoms(Structure.from_dict(atoms))\n",
    "    return Graph.atom_dgl_multigraph(\n",
    "        structure,\n",
    "        cutoff=cutoff,\n",
    "        atom_features=atom_features,\n",
    "        max_neighbors=max_neighbors,\n",
    "        compute_line_graph=True,\n",
    "        use_canonize=use_canonize,\n",
    "    )\n",
    "\n",
    "def group_decay(model):\n",
    "    \"\"\"Omit weight decay from bias and batchnorm params.\"\"\"\n",
    "    decay, no_decay = [], []\n",
    "\n",
    "    for name, p in model.named_parameters():\n",
    "        if \"bias\" in name or \"bn\" in name or \"norm\" in name:\n",
    "            no_decay.append(p)\n",
    "        else:\n",
    "            decay.append(p)\n",
    "\n",
    "    return [\n",
    "        {\"params\": decay},\n",
    "        {\"params\": no_decay, \"weight_decay\": 0},\n",
    "    ]\n",
    "\n",
    "def collate_line_graph(samples):\n",
    "        \"\"\"Dataloader helper to batch graphs cross `samples`.\"\"\"\n",
    "        graphs, line_graphs, labels = map(list, zip(*samples))\n",
    "        batched_graph = dgl.batch(graphs)\n",
    "        batched_line_graph = dgl.batch(line_graphs)\n",
    "        print(labels[0])\n",
    "        print(labels[0].size())\n",
    "        if len(labels[0].size()) > 0:\n",
    "            return batched_graph, batched_line_graph, torch.stack(labels)\n",
    "        else:\n",
    "            return batched_graph, batched_line_graph, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f25ea7-ead8-4554-93fb-bb43da5220bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = '../data/No-dup-complete_dataset_100.json'\n",
    "with open(data, \"rb\") as f:\n",
    "    dataset = json.loads(f.read())\n",
    "    \n",
    "for datum in tqdm_notebook(dataset):\n",
    "    datum['atoms'] = atoms_to_graph(datum['structure'], cutoff=10.0)\n",
    "    datum['has_prop'] = torch.FloatTensor(datum['OH']) #torch.FloatTensor(random.choices([0, 1], k=6))\n",
    "    datum['target'] = torch.FloatTensor(datum['prop_list'])#random.sample(list(np.arange(-1, 1, 1e-4)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa17652-e809-487e-8d6b-7b04d400f082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ALIGNN(n_outputs=7)\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e103af-fec5-4abe-a200-25a915c4bd6b",
   "metadata": {},
   "source": [
    "## Load an old model\n",
    "\n",
    "Uncomment the next lines if you want to reload a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a19138-b18f-4708-870e-56df8aa5dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('./best_model.pt', map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd1260-67c4-4358-a017-237380e8b038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split = 60\n",
    "test_split = 80\n",
    "\n",
    "Xtrain = [d['atoms'] for d in dataset[:train_split]]\n",
    "Ptrain = [d['has_prop'] for d in dataset[:train_split]]\n",
    "ytrain = [d['target'] for d in dataset[:train_split]]\n",
    "\n",
    "Xval = [d['atoms'] for d in dataset[train_split:test_split]]\n",
    "Pval = [d['has_prop'] for d in dataset[train_split:test_split]]\n",
    "yval = [d['target'] for d in dataset[train_split:test_split]]\n",
    "\n",
    "Xtest = [d['atoms'] for d in dataset[test_split:]]\n",
    "Ptest = [d['has_prop'] for d in dataset[test_split:]]\n",
    "ytest = [d['target'] for d in dataset[test_split:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f377a6-bac2-4f08-aa2c-084118369209",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Train/Eval Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe8801-cfa0-4566-9d88-b17f90c4eabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First set up the optimiser, loss and device\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "params = group_decay(model)\n",
    "optimizer = torch.optim.AdamW(params, lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562d02c-fe07-43c7-9f57-3521a9f4b23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 12    # number of epochs to run\n",
    "batch_size = 1  # size of each batch\n",
    "batches_per_epoch = len(Xtrain) // batch_size\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss = 0\n",
    "    print('Epoch Number ', epoch)\n",
    "    for i in tqdm_notebook(range(batches_per_epoch)):\n",
    "        start = i * batch_size\n",
    "        # take a batch\n",
    "        Xbatch = Xtrain[start:start+batch_size]\n",
    "        Propbatch = Ptrain[start:start+batch_size]\n",
    "        ybatch = ytrain[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(Xbatch[0], Propbatch[0])\n",
    "        #print(y_pred, ybatch)\n",
    "        loss = criterion(y_pred, ybatch[0])\n",
    "        training_loss += loss\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "    training_loss = training_loss / len(Xtrain)\n",
    "    print('Training loss: %.3f'% training_loss.item())\n",
    "    training_losses.append(training_loss.item())\n",
    "    val_loss = 0\n",
    "    for i, true in enumerate(yval):\n",
    "        y_pred = model(Xval[i], Pval[i])\n",
    "        val_loss += criterion(true, y_pred)\n",
    "    val_loss = val_loss / i\n",
    "    print('Validation loss: %.3f'% val_loss.item())\n",
    "    validation_losses.append(val_loss.item())\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        print('Model improved, saving')\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee436ee-9caf-4c1e-ab4c-780b62b9f86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
